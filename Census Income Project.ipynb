{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Census Income Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descritpion:  In this dataset, classes are ordered, but it was not balanced. Who is making more then 50K $ income per, who are not \n",
    "\n",
    "These are the name of Features from the dataset -:\n",
    "\n",
    "    Age\t\n",
    "    Workclass\n",
    "    Fnlwgt\n",
    "    Education\n",
    "    Education_num\n",
    "    Marital_status\n",
    "    Occupation\n",
    "    Relationship\n",
    "    Race\t\n",
    "    Sex\n",
    "    Capital_gain\n",
    "    Capital_loss\t\n",
    "    Hours_per_week\n",
    "    Native_country\n",
    "    Income\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import zscore\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data set\n",
    "df= pd.read_csv('census_income.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: Dataset contains the 32560 reocrds 15 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: Dataset contains the object and interger data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: \n",
    "1. dataset contains no null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heat map to check the null values\n",
    "plt.figure(figsize=[16,8])\n",
    "sns.heatmap(df.isnull(), cbar=False)\n",
    "plt.title('Null values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: \n",
    "1. No variable columns contains missing and null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Income'].value_counts())\n",
    "sns.countplot(df['Income'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OObservation: People who makes greater then 50K population is 7841 and who makes less then 50K is 24719"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Occupation'].value_counts(normalize=False)[:15].plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: Highest population of occuption is the Prof -speciality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Marital_status'].value_counts(normalize=False)[:15].plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(df, x_vars=['Education_num','Fnlwgt','Hours_per_week'], y_vars='Income', size=7, aspect=0.7, kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['Income'],df['Education'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observaion: Highest number of people who completed the HS-grad and lowest is the Preshcool\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data points\n",
    "sns.countplot(df[\"Occupation\"],)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['Occupation'], df['Education'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: We can see the data ditributed normally  occutption education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding the Cateogorical variables \n",
    "#label encoding \n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "le = LabelEncoder()\n",
    "\n",
    "#df_train = pd.get_dummies(df_train, columns=['Profile'])\n",
    "df['Workclass'] = le.fit_transform(df['Workclass'])\n",
    "df['Education'] = le.fit_transform(df['Education'])\n",
    "df['Marital_status'] = le.fit_transform(df['Marital_status'])\n",
    "df['Occupation'] = le.fit_transform(df['Occupation'])\n",
    "df['Relationship'] = le.fit_transform(df['Relationship'])\n",
    "df['Race'] = le.fit_transform(df['Race'])\n",
    "df['Sex'] = le.fit_transform(df['Sex'])\n",
    "df['Native_country'] = le.fit_transform(df['Native_country'])\n",
    "df['Income'] = le.fit_transform(df['Income'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#if you only have two choices to select from:\n",
    "\n",
    "#df['>50K'] = np.where(df['Income']=='>50K', '0', '1')\n",
    "\n",
    "#df['>50K'] = ['1' if x == '>50K' else '0' for x in df['Income']]\n",
    "\n",
    "\n",
    "conditions = [\n",
    "    (df['Income'] == '>50K'),\n",
    "    (df['Income'] == '<=50K')]\n",
    "\n",
    "choices = ['1', '0']\n",
    "df['Greater'] = np.select(conditions, choices)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot histogram\n",
    "df.hist(bins=20,figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To check the corr_mat  Heatmap\n",
    "corr_hmap=df.corr()\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(corr_hmap, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to display the\n",
    "corr_matrix=df.corr()\n",
    "corr_matrix['Income'].sort_values(ascending = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBservation:\n",
    "1. Education number have positive relationship with target varibles income 33%\n",
    "2. Education number, age, Hours_per_week,Capital_gain,Sex,Capital_loss,Education,Occupation,Race, Workclass, Native_country, ALso  have positive reaionship with Income\n",
    "3. FnlGHT, Merital_status, relationship negative relationship income\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns =['Age', 'Workclass', 'Fnlwgt', 'Education', 'Education_num',\n",
    "       'Marital_status', 'Occupation', 'Relationship', 'Race', 'Sex',\n",
    "       'Capital_gain', 'Capital_loss', 'Hours_per_week', 'Native_country',\n",
    "       'Income']\n",
    "        \n",
    "for i in df[columns]:\n",
    "    plt.figure()\n",
    "    sns.distplot(df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting the data into x and y\n",
    "\n",
    "x =df.drop(['Income'],axis=1)\n",
    "y=df['Income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train test splits\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "#NOrmalizing the data using minmax scaler\n",
    "  \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# creating scaler scale var.\n",
    "norm = MinMaxScaler()\n",
    "# fit the scal\n",
    "norm_fit = norm.fit(x_train)\n",
    "# transfromation of trainig data\n",
    "scal_xtrain = norm_fit.transform(x_train)\n",
    "# transformation of testing data\n",
    "scal_xtest = norm_fit.transform(x_test)\n",
    "print(scal_xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "from collections import Counter\n",
    "#import imblearn\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "counter =Counter(y_train)\n",
    "print('Before', counter)\n",
    "\n",
    "smote = SMOTE()\n",
    "\n",
    "x_smote, y_smote = smote.fit_resample(x, y)\n",
    "\n",
    "counter =Counter(y_smote)\n",
    "print('after', counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision Tree model \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt=DecisionTreeClassifier()\n",
    "#dt.fit(x_smote,y_smote)   #over sampled data using here\n",
    "dt.fit(x_train,y_train)\n",
    "p=dt.predict(x_test)\n",
    "print(accuracy_score(y_test,p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression \n",
    "#Model building\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lg=LogisticRegression()\n",
    "#lg.fit(x_smote,y_smote)   #minority class balanced data \n",
    "lg.fit(x_train,y_train)\n",
    "pred =lg.predict(x_test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy_score\", accuracy_score(y_test,pred))\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC ROC CURVE\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob =lg.predict_proba(x_test)[:,1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr,tpr,thresholds =roc_curve(y_test,y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr,tpr,label='Logistic Regression')\n",
    "plt.xlabel('Not good wine ')\n",
    "plt.ylabel('Good wine ')\n",
    "plt.title('Losgistic Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "score=cross_val_score(dt, x,y, cv=5)\n",
    "print(score)\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf=RandomForestClassifier(n_estimators=100)\n",
    "#rf.fit(x_smote, y_smote)  #balanced data\n",
    "rf.fit(x_train, y_train)\n",
    "y _pred=rf.predict(x_test)\n",
    "print('accuracy score', pred)\n",
    "print(accuracy_score(y_test,pred))\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "1. we are getting the accuracy 91% using imbalanced data \n",
    "2. we getting the accuracy 100% using minority classs balanced data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the svm model\n",
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(x_train, y_train)\n",
    "#svclassifier.fit(x_smote, y_smote)  #balanced data\n",
    "y_pred = svclassifier.predict(x_test)\n",
    "print(accuracy_score(y_test,pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "1. we are getting the accuracy 100% using imbalanced data \n",
    "2. we getting the accuracy 100% using minority classs balanced data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the Model----\n",
    "SVC model getting the highest accuarcy so we are saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "# Save the model as a pickle in a file\n",
    "joblib.dump(svclassifier, 'svclassifier.pkl')\n",
    "  \n",
    "# Load the model from the file\n",
    "svclassifier_joblib = joblib.load('svclassifier.pkl') \n",
    "  \n",
    "# Use the loaded model to make predictions\n",
    "#svclassifier_joblib.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
