{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bs4\n",
    "#!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page =requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup =BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the tags\n",
    "heading=soup.find('h2', id=\"mp-tfa-h2\")\n",
    "#heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From today's featured article\""
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separtaing the text from the tag\n",
    "heading.text.replace('\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "heading =soup.find_all('span', class_=\"mw-headline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "headings=[] #empty list for stare the \n",
    "for i in heading:\n",
    "    headings.append(i.text)\n",
    "    \n",
    "#headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    From today's featured article\n",
       "1                 Did you know ...\n",
       "2                      In the news\n",
       "3                      On this day\n",
       "4         Today's featured picture\n",
       "Name: Headings, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Wiki =pd.DataFrame({})\n",
    "Wiki['Headings']= headings\n",
    "\n",
    "\n",
    "Wiki['Headings'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_name =requests.get('https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc')\n",
    "soup =BeautifulSoup(movies_name.content, 'html.parser')\n",
    "movies_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for URL links \n",
    "\n",
    "url_tags =soup.find_all('div', class_=\"desc\") #Extract next page URl\n",
    "#url_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/search/title/?groups=top_100&sort=user_rating,desc&start=51',\n",
       " '/search/title/?groups=top_100&sort=user_rating,desc&start=51']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to get URLS\n",
    "urls =[]\n",
    "for i in url_tags:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        urls.append(j['href'])\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc&start=51&ref_=adv_nxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scarp data from multiple pages\n",
    "\n",
    "Movies_names =[] #empty list\n",
    "\n",
    "movies_name = requests.get(\"https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc\")\n",
    "soup = BeautifulSoup(movies_name.content, 'html.parser')\n",
    "movies_name = soup.find_all(\"h3\", class_=\"lister-item-header\") \n",
    "    \n",
    "for i in movies_name:\n",
    "    Movies_names.append(i.text.replace(\"\\n\",\" \"))\n",
    "        \n",
    "#Movies_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "Movies_names1 =[]\n",
    "movies_name1 =requests.get(\"https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc&start=51&ref_=adv_nxt\")\n",
    "soup = BeautifulSoup(movies_name1.content, 'html.parser')\n",
    "movies_name1=soup.find_all(\"h3\", class_=\"lister-item-header\")\n",
    "for i in movies_name1:\n",
    "    Movies_names1.append(i.text.replace(\"\\n\",\" \"))\n",
    "    \n",
    "#Movies_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "Movies =pd.DataFrame({})\n",
    "Movies['Name'] = Movies_names + Movies_names1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the new column IMDB ranking \n",
    "\n",
    "Movies['IMDB_Ranking']= Movies['Name'].str[0:3]\n",
    "Movies['Year']= Movies['Name'].str[-6:-2]\n",
    "Movies['Name']= Movies['Name'].str[3:-7]\n",
    "#Movies['IMDB_Ranking']\n",
    "#Movies['Year']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>IMDB_Ranking</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1.</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>2.</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>3.</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>4.</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>5.</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>6.</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>7.</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>8.</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Inception</td>\n",
       "      <td>9.</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>. Fight Club</td>\n",
       "      <td>10</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>. The Lord of the Rings: The Fellowship of the...</td>\n",
       "      <td>11</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>. Forrest Gump</td>\n",
       "      <td>12</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>. Il buono, il brutto, il cattivo</td>\n",
       "      <td>13</td>\n",
       "      <td>1966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>. The Lord of the Rings: The Two Towers</td>\n",
       "      <td>14</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>. The Matrix</td>\n",
       "      <td>15</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>. Goodfellas</td>\n",
       "      <td>16</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>. Star Wars: Episode V - The Empire Strikes Back</td>\n",
       "      <td>17</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>. One Flew Over the Cuckoo's Nest</td>\n",
       "      <td>18</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>. Gisaengchung</td>\n",
       "      <td>19</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>. Interstellar</td>\n",
       "      <td>20</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>. Cidade de Deus</td>\n",
       "      <td>21</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>. Sen to Chihiro no kamikakushi</td>\n",
       "      <td>22</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>. Saving Private Ryan</td>\n",
       "      <td>23</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>. The Green Mile</td>\n",
       "      <td>24</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>. La vita è bella</td>\n",
       "      <td>25</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>. Se7en</td>\n",
       "      <td>26</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>. The Silence of the Lambs</td>\n",
       "      <td>27</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>. Star Wars</td>\n",
       "      <td>28</td>\n",
       "      <td>1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>. Seppuku</td>\n",
       "      <td>29</td>\n",
       "      <td>1962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>. Pather Panchali</td>\n",
       "      <td>30</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>. Raiders of the Lost Ark</td>\n",
       "      <td>71</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>. The Shining</td>\n",
       "      <td>72</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>. Apocalypse Now</td>\n",
       "      <td>73</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>. Alien</td>\n",
       "      <td>74</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>. Tengoku to jigoku</td>\n",
       "      <td>75</td>\n",
       "      <td>1963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>. Dr. Strangelove or: How I Learned to Stop Wo...</td>\n",
       "      <td>76</td>\n",
       "      <td>1964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>. Witness for the Prosecution</td>\n",
       "      <td>77</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>. Paths of Glory</td>\n",
       "      <td>78</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>. Sunset Blvd.</td>\n",
       "      <td>79</td>\n",
       "      <td>1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>. The Great Dictator</td>\n",
       "      <td>80</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>. Jagten</td>\n",
       "      <td>81</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>. Inglourious Basterds</td>\n",
       "      <td>82</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>. Eternal Sunshine of the Spotless Mind</td>\n",
       "      <td>83</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>. Requiem for a Dream</td>\n",
       "      <td>84</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>. American Beauty</td>\n",
       "      <td>85</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>. Good Will Hunting</td>\n",
       "      <td>86</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>. Toy Story</td>\n",
       "      <td>87</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>. Braveheart</td>\n",
       "      <td>88</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>. Reservoir Dogs</td>\n",
       "      <td>89</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>. Idi i smotri</td>\n",
       "      <td>90</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>. Aliens</td>\n",
       "      <td>91</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>. Amadeus</td>\n",
       "      <td>92</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>. Star Wars: Episode VI - Return of the Jedi</td>\n",
       "      <td>93</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>. Das Boot</td>\n",
       "      <td>94</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>. 2001: A Space Odyssey</td>\n",
       "      <td>95</td>\n",
       "      <td>1968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>. North by Northwest</td>\n",
       "      <td>96</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>. Vertigo</td>\n",
       "      <td>97</td>\n",
       "      <td>1958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>. Singin' in the Rain</td>\n",
       "      <td>98</td>\n",
       "      <td>1952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>. Citizen Kane</td>\n",
       "      <td>99</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0. M - Eine Stadt sucht einen Mörder</td>\n",
       "      <td>10</td>\n",
       "      <td>1931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name IMDB_Ranking  Year\n",
       "0                           The Shawshank Redemption            1.  1994\n",
       "1                                      The Godfather            2.  1972\n",
       "2                                    The Dark Knight            3.  2008\n",
       "3                             The Godfather: Part II            4.  1974\n",
       "4                                       12 Angry Men            5.  1957\n",
       "5      The Lord of the Rings: The Return of the King            6.  2003\n",
       "6                                       Pulp Fiction            7.  1994\n",
       "7                                   Schindler's List            8.  1993\n",
       "8                                          Inception            9.  2010\n",
       "9                                       . Fight Club            10  1999\n",
       "10  . The Lord of the Rings: The Fellowship of the...           11  2001\n",
       "11                                    . Forrest Gump            12  1994\n",
       "12                 . Il buono, il brutto, il cattivo            13  1966\n",
       "13           . The Lord of the Rings: The Two Towers            14  2002\n",
       "14                                      . The Matrix            15  1999\n",
       "15                                      . Goodfellas            16  1990\n",
       "16  . Star Wars: Episode V - The Empire Strikes Back            17  1980\n",
       "17                 . One Flew Over the Cuckoo's Nest            18  1975\n",
       "18                                    . Gisaengchung            19  2019\n",
       "19                                    . Interstellar            20  2014\n",
       "20                                  . Cidade de Deus            21  2002\n",
       "21                   . Sen to Chihiro no kamikakushi            22  2001\n",
       "22                             . Saving Private Ryan            23  1998\n",
       "23                                  . The Green Mile            24  1999\n",
       "24                                 . La vita è bella            25  1997\n",
       "25                                           . Se7en            26  1995\n",
       "26                        . The Silence of the Lambs            27  1991\n",
       "27                                       . Star Wars            28  1977\n",
       "28                                         . Seppuku            29  1962\n",
       "29                                 . Pather Panchali            30  1955\n",
       "..                                                ...          ...   ...\n",
       "70                         . Raiders of the Lost Ark            71  1981\n",
       "71                                     . The Shining            72  1980\n",
       "72                                  . Apocalypse Now            73  1979\n",
       "73                                           . Alien            74  1979\n",
       "74                               . Tengoku to jigoku            75  1963\n",
       "75  . Dr. Strangelove or: How I Learned to Stop Wo...           76  1964\n",
       "76                     . Witness for the Prosecution            77  1957\n",
       "77                                  . Paths of Glory            78  1957\n",
       "78                                    . Sunset Blvd.            79  1950\n",
       "79                              . The Great Dictator            80  1940\n",
       "80                                          . Jagten            81  2012\n",
       "81                            . Inglourious Basterds            82  2009\n",
       "82           . Eternal Sunshine of the Spotless Mind            83  2004\n",
       "83                             . Requiem for a Dream            84  2000\n",
       "84                                 . American Beauty            85  1999\n",
       "85                               . Good Will Hunting            86  1997\n",
       "86                                       . Toy Story            87  1995\n",
       "87                                      . Braveheart            88  1995\n",
       "88                                  . Reservoir Dogs            89  1992\n",
       "89                                    . Idi i smotri            90  1985\n",
       "90                                          . Aliens            91  1986\n",
       "91                                         . Amadeus            92  1984\n",
       "92      . Star Wars: Episode VI - Return of the Jedi            93  1983\n",
       "93                                        . Das Boot            94  1981\n",
       "94                           . 2001: A Space Odyssey            95  1968\n",
       "95                              . North by Northwest            96  1959\n",
       "96                                         . Vertigo            97  1958\n",
       "97                             . Singin' in the Rain            98  1952\n",
       "98                                    . Citizen Kane            99  1941\n",
       "99              0. M - Eine Stadt sucht einen Mörder            10  1931\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Movies.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "Indian_movies =[] #empty list\n",
    "\n",
    "indian_movies_name = requests.get(\"https://www.imdb.com/india/top-rated-indian-movies/\")\n",
    "soup = BeautifulSoup(indian_movies_name.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_movies_name = soup.find_all(\"td\", class_=\"titleColumn\") \n",
    "    \n",
    "for i in indian_movies_name:\n",
    "    Indian_movies.append(i.text.replace(\"\\n\",\" \"))\n",
    "        \n",
    "#Indian_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top_Indian_Movies =pd.DataFrame({})\n",
    "Top_Indian_Movies['Name'] = Indian_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the new column IMDB ranking \n",
    "\n",
    "Top_Indian_Movies['IMDB_Ranking']= Top_Indian_Movies['Name'].str[6:10]\n",
    "Top_Indian_Movies['Year']= Top_Indian_Movies['Name'].str[-6:-2]\n",
    "Top_Indian_Movies['Name']= Top_Indian_Movies['Name'].str[9:-7]\n",
    "#Top_Indian_Movies['IMDB_Ranking']\n",
    "#Movies['Year']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>IMDB_Ranking</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pather Panchali</td>\n",
       "      <td>1.</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>2.</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pariyerum Perumal</td>\n",
       "      <td>3.</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>4.</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Golmaal</td>\n",
       "      <td>5.</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Apur Sansar</td>\n",
       "      <td>6.</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C/o Kancharapalem</td>\n",
       "      <td>7.</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kireedam</td>\n",
       "      <td>8.</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Manichitrathazhu</td>\n",
       "      <td>9.</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>.       Natsamrat</td>\n",
       "      <td>10.</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>.       Drishyam 2</td>\n",
       "      <td>11.</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>.       96</td>\n",
       "      <td>12.</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>.       Black Friday</td>\n",
       "      <td>13.</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>.       Thevar Magan</td>\n",
       "      <td>14.</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>.       Kumbalangi Nights</td>\n",
       "      <td>15.</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>.       3 Idiots</td>\n",
       "      <td>16.</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>.       Visaaranai</td>\n",
       "      <td>17.</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>.       Taare Zameen Par</td>\n",
       "      <td>18.</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>.       Jersey</td>\n",
       "      <td>19.</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>.       Ratsasan</td>\n",
       "      <td>20.</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>.       Thalapathi</td>\n",
       "      <td>21.</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>.       Dangal</td>\n",
       "      <td>22.</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>.       Soorarai Pottru</td>\n",
       "      <td>23.</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>.       Asuran</td>\n",
       "      <td>24.</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>.       Kaithi</td>\n",
       "      <td>25.</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>.       Aparajito</td>\n",
       "      <td>26.</td>\n",
       "      <td>1956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>.       Devasuram</td>\n",
       "      <td>27.</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>.       Jaane Bhi Do Yaaro</td>\n",
       "      <td>28.</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>.       Pyaasa</td>\n",
       "      <td>29.</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>.       Peranbu</td>\n",
       "      <td>30.</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>.       Ustad Hotel</td>\n",
       "      <td>71.</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>.       Nil Battey Sannata</td>\n",
       "      <td>72.</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>.       Jo Jeeta Wohi Sikandar</td>\n",
       "      <td>73.</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>.       Charulata</td>\n",
       "      <td>74.</td>\n",
       "      <td>1964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>.       Drishyam</td>\n",
       "      <td>75.</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>.       Mughal-E-Azam</td>\n",
       "      <td>76.</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>.       Maheshinte Prathikaaram</td>\n",
       "      <td>77.</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>.       Zindagi Na Milegi Dobara</td>\n",
       "      <td>78.</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>.       Article 15</td>\n",
       "      <td>79.</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>.       Udaan</td>\n",
       "      <td>80.</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>.       A Wednesday</td>\n",
       "      <td>81.</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>.       Theeran adhigaaram ondru</td>\n",
       "      <td>82.</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>.       Queen</td>\n",
       "      <td>83.</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>.       Masaan</td>\n",
       "      <td>84.</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>.       Sarfarosh</td>\n",
       "      <td>85.</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>.       Munna Bhai M.B.B.S.</td>\n",
       "      <td>86.</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>.       Alai Payuthey</td>\n",
       "      <td>87.</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>.       Dil Chahta Hai</td>\n",
       "      <td>88.</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>.       Roja</td>\n",
       "      <td>89.</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>.       OMG: Oh My God!</td>\n",
       "      <td>90.</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>.       Baasha</td>\n",
       "      <td>91.</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>.       Rang De Basanti</td>\n",
       "      <td>92.</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>.       Lagaan: Once Upon a Time in India</td>\n",
       "      <td>93.</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>.       Kahaani</td>\n",
       "      <td>94.</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>.       Andaz Apna Apna</td>\n",
       "      <td>95.</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>.       Chhichhore</td>\n",
       "      <td>96.</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>.       Uri: The Surgical Strike</td>\n",
       "      <td>97.</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>.       Virumandi</td>\n",
       "      <td>98.</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>.       PK</td>\n",
       "      <td>99.</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.       Lucia</td>\n",
       "      <td>100</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Name IMDB_Ranking  Year\n",
       "0                             Pather Panchali           1.   1955\n",
       "1                                     Nayakan           2.   1987\n",
       "2                           Pariyerum Perumal           3.   2018\n",
       "3                                  Anbe Sivam           4.   2003\n",
       "4                                     Golmaal           5.   1979\n",
       "5                                 Apur Sansar           6.   1959\n",
       "6                           C/o Kancharapalem           7.   2018\n",
       "7                                    Kireedam           8.   1989\n",
       "8                            Manichitrathazhu           9.   1993\n",
       "9                           .       Natsamrat           10.  2016\n",
       "10                         .       Drishyam 2           11.  2021\n",
       "11                                 .       96           12.  2018\n",
       "12                       .       Black Friday           13.  2004\n",
       "13                       .       Thevar Magan           14.  1992\n",
       "14                  .       Kumbalangi Nights           15.  2019\n",
       "15                           .       3 Idiots           16.  2009\n",
       "16                         .       Visaaranai           17.  2015\n",
       "17                   .       Taare Zameen Par           18.  2007\n",
       "18                             .       Jersey           19.  2019\n",
       "19                           .       Ratsasan           20.  2018\n",
       "20                         .       Thalapathi           21.  1991\n",
       "21                             .       Dangal           22.  2016\n",
       "22                    .       Soorarai Pottru           23.  2020\n",
       "23                             .       Asuran           24.  2019\n",
       "24                             .       Kaithi           25.  2019\n",
       "25                          .       Aparajito           26.  1956\n",
       "26                          .       Devasuram           27.  1993\n",
       "27                 .       Jaane Bhi Do Yaaro           28.  1983\n",
       "28                             .       Pyaasa           29.  1957\n",
       "29                            .       Peranbu           30.  2018\n",
       "..                                         ...          ...   ...\n",
       "70                        .       Ustad Hotel           71.  2012\n",
       "71                 .       Nil Battey Sannata           72.  2015\n",
       "72             .       Jo Jeeta Wohi Sikandar           73.  1992\n",
       "73                          .       Charulata           74.  1964\n",
       "74                           .       Drishyam           75.  2015\n",
       "75                      .       Mughal-E-Azam           76.  1960\n",
       "76            .       Maheshinte Prathikaaram           77.  2016\n",
       "77           .       Zindagi Na Milegi Dobara           78.  2011\n",
       "78                         .       Article 15           79.  2019\n",
       "79                              .       Udaan           80.  2010\n",
       "80                        .       A Wednesday           81.  2008\n",
       "81           .       Theeran adhigaaram ondru           82.  2017\n",
       "82                              .       Queen           83.  2013\n",
       "83                             .       Masaan           84.  2015\n",
       "84                          .       Sarfarosh           85.  1999\n",
       "85                .       Munna Bhai M.B.B.S.           86.  2003\n",
       "86                      .       Alai Payuthey           87.  2000\n",
       "87                     .       Dil Chahta Hai           88.  2001\n",
       "88                               .       Roja           89.  1992\n",
       "89                    .       OMG: Oh My God!           90.  2012\n",
       "90                             .       Baasha           91.  1995\n",
       "91                    .       Rang De Basanti           92.  2006\n",
       "92  .       Lagaan: Once Upon a Time in India           93.  2001\n",
       "93                            .       Kahaani           94.  2012\n",
       "94                    .       Andaz Apna Apna           95.  1994\n",
       "95                         .       Chhichhore           96.  2019\n",
       "96           .       Uri: The Surgical Strike           97.  2018\n",
       "97                          .       Virumandi           98.  2004\n",
       "98                                 .       PK           99.  2014\n",
       "99                             0.       Lucia           100  2013\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_Indian_Movies.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Write a python program to scrap book name, author name, genre and book review of any 5 books from\n",
    "‘www.bookpage.com’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "Book_names =[] #empty list\n",
    "\n",
    "book = requests.get(\"https://bookpage.com/reviews\")\n",
    "soup = BeautifulSoup(book.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = soup.find_all(\"h4\", class_=\"italic\") #scarp th book names\n",
    "Book_names=[]\n",
    "\n",
    "for i in book:\n",
    "    Book_names.append(i.text.replace(\"\\n\",\" \"))\n",
    "        \n",
    "len(Book_names)\n",
    "\n",
    "Book_names=Book_names[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_author = soup.find_all(\"p\", class_=\"sans bold\") \n",
    "Book_Author=[]\n",
    "\n",
    "for i in book_author:\n",
    "    Book_Author.append(i.text.replace(\"\\n\",\" \"))\n",
    "        \n",
    "#Book_Author\n",
    "len(Book_Author)\n",
    "Book_Author=Book_Author[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = soup.find_all(\"p\", class_=\"genre-links hidden-phone\")\n",
    "Genre = [ ]\n",
    "for i in genre:\n",
    "    Genre.append(i.text.replace(\"\\n\",\" \"))\n",
    "        \n",
    "#Genre\n",
    "len(Genre)\n",
    "Genre =Genre[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "review =requests.get('https://bookpage.com/reviews/')\n",
    "soup =BeautifulSoup(review.content, 'html.parser')\n",
    "\n",
    "url_tags =soup.find_all(\"div\", class_=\"read-full\") #Extract next page URl\n",
    "#url_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls =[]\n",
    "for i in url_tags:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        urls.append(j['href'])\n",
    "#urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scarp data from multiple pages\n",
    "URL = ['https://bookpage.com/reviews/26318-curtis-manley-rescuer-tiny-creatures-childrens#.YLZPaagzbDc','https://bookpage.com/reviews/26318-curtis-manley-rescuer-tiny-creatures-childrens#.YLZPaagzbDc',\n",
    "       'https://bookpage.com/reviews/26295-kristen-arnett-with-teeth-fiction#.YLZPsKgzbDc','https://bookpage.com/reviews/26359-t-l-huchu-library-dead-science-fiction-fantasy',\n",
    "       'https://bookpage.com/reviews/26323-caroline-odonoghue-all-our-hidden-gifts-ya#.YLZP7KgzbDc','https://bookpage.com/reviews/26302-jess-mchugh-americanon-nonfiction#.YLZQD6gzbDc',\n",
    "       'https://bookpage.com/reviews/26321-nghi-vo-chosen-beautiful-science-fiction-fantasy#.YLZQLKgzbDc']\n",
    "\n",
    "Review =[ ] #empty list\n",
    "\n",
    "for url in URL:\n",
    "    review = requests.get(url)\n",
    "    soup = BeautifulSoup(review.text, 'html.parser')\n",
    "    \n",
    "    review = soup.find_all(\"div\", class_=\"article-body\") \n",
    "    \n",
    "    for i in review:\n",
    "        Review.append(i.text.replace(\"\\n\",\" \"))\n",
    "len(Review)\n",
    "Review =Review[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Book_details =pd.DataFrame({'Book_Names':[ ],'Book_Author':[ ],'Book_review':[ ],'Genre': [ ]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Book_details['Book_Names'] = Book_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Book_details['Book_Author'] = Book_Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Book_details['Genre'] = Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "Book_details['Book_review'] = Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_Names</th>\n",
       "      <th>Book_Author</th>\n",
       "      <th>Book_review</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>★ Walking on Cowrie Shells</td>\n",
       "      <td>Nana Nkweti</td>\n",
       "      <td>Red-haired, inquisitive Roberta is a budding...</td>\n",
       "      <td>Fiction  /  Short Stories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malibu Rising</td>\n",
       "      <td>Taylor Jenkins Reid</td>\n",
       "      <td>Red-haired, inquisitive Roberta is a budding...</td>\n",
       "      <td>Fiction  /  Popular Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Both Can Be True</td>\n",
       "      <td>Jules Machias</td>\n",
       "      <td>Kristen Arnett delivers a fantastic follow-u...</td>\n",
       "      <td>Children's  /  Middle Grade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>★ The One Hundred Years of Lenni and Margot</td>\n",
       "      <td>Marianne Cronin</td>\n",
       "      <td>T.L. Huchu’s first installment of the Edinbu...</td>\n",
       "      <td>Fiction  /  Popular Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We Can’t Keep Meeting Like This</td>\n",
       "      <td>Rachel Lynn Solomon</td>\n",
       "      <td>When Maeve is tasked with cleaning out a sto...</td>\n",
       "      <td>YA  /  YA Fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Book_Names            Book_Author  \\\n",
       "0                     ★ Walking on Cowrie Shells            Nana Nkweti    \n",
       "1                                  Malibu Rising    Taylor Jenkins Reid    \n",
       "2                               Both Can Be True          Jules Machias    \n",
       "3    ★ The One Hundred Years of Lenni and Margot        Marianne Cronin    \n",
       "4                We Can’t Keep Meeting Like This    Rachel Lynn Solomon    \n",
       "\n",
       "                                         Book_review  \\\n",
       "0    Red-haired, inquisitive Roberta is a budding...   \n",
       "1    Red-haired, inquisitive Roberta is a budding...   \n",
       "2    Kristen Arnett delivers a fantastic follow-u...   \n",
       "3    T.L. Huchu’s first installment of the Edinbu...   \n",
       "4    When Maeve is tasked with cleaning out a sto...   \n",
       "\n",
       "                           Genre  \n",
       "0     Fiction  /  Short Stories   \n",
       "1   Fiction  /  Popular Fiction   \n",
       "2   Children's  /  Middle Grade   \n",
       "3   Fiction  /  Popular Fiction   \n",
       "4             YA  /  YA Fiction   "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Book_details.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Top 10 ODI teams in men’s cricket along with the records for matches, points and rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scarp data from multiple pages\n",
    "\n",
    "cricket = requests.get(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")\n",
    "soup = BeautifulSoup(cricket.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket = soup.find_all(\"tr\", class_=\"table-body\") \n",
    "Top10_team = []\n",
    "\n",
    "for i in cricket:\n",
    "    Top10_team.append(i.text.replace(\"\\n\",\" \"))\n",
    "        \n",
    "#Top10_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Top10_teams =pd.DataFrame({})\n",
    "Top10_teams['Team_Names'] = Top10_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top10_teams[['Rank','team_names','Matches','Points','Rating']] = Top10_teams[\"Team_Names\"].str.split(\" \", 1, expand=True)\n",
    "#Top10_teams[\"Team_Names\"] = Top10_teams[\"Team_Names\"].str.strip(\" \")\n",
    "#Top10_teams[['Rank','team_names']] = Top10_teams['Team_Names'].str.split(n=1, expand=True)\n",
    "#df['col2'] = df['col2'].str.split().str[-1]\n",
    "#print(Top10_teams)\n",
    "\n",
    "#Top10_teams[['Rank','team_names','Matches','Points','Rating']] = Top10_teams.Team_Names.str.extract(' (.*\\d+)\\s-?\\s?(.*)', expand=True)\n",
    "\n",
    "#keeptemp  =  Top10_teams['Team_Names'].str.split('\\n {4,}', expand = T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2   Australia AUS  25 2,945 118 \n",
       "1            3   India IND  29 3,344 115 \n",
       "2          4   England ENG  27 3,100 115 \n",
       "3      5   South Africa SA  20 2,137 107 \n",
       "4          6   Pakistan PAK  24 2,323 97 \n",
       "5        7   Bangladesh BAN  27 2,438 90 \n",
       "6        8   West Indies WI  27 2,222 82 \n",
       "7          9   Sri Lanka SL  24 1,876 78 \n",
       "8      10   Afghanistan AFG  17 1,054 62 \n",
       "9         11   Netherlands NED  5 249 50 \n",
       "10           12   Ireland IRE  19 807 42 \n",
       "11          13   Zimbabwe ZIM  15 588 39 \n",
       "12           14   Scotland SCO  7 258 37 \n",
       "13               15   Oman OMA  7 240 34 \n",
       "14              16   Nepal NEP  5 119 24 \n",
       "15                17   UAE UAE  9 190 21 \n",
       "16             18   Namibia NAM  6 97 16 \n",
       "17       19   United States USA  8 93 12 \n",
       "18      20   Papua New Guinea PNG  5 0 0 \n",
       "Name: Team_Names, dtype: object"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top10_teams[\"Team_Names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top10_teams['Team_rank']= Top10_teams['Team_Names'].str[1:4]\n",
    "Top10_teams['Rating']= Top10_teams['Team_Names'].str[-4:-1]\n",
    "Top10_teams['Points']= Top10_teams['Team_Names'].str[-10:-5]\n",
    "Top10_teams['Matches']= Top10_teams['Team_Names'].str[-13:-10]\n",
    "Top10_teams['Team_Names']= Top10_teams['Team_Names'].str[2:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_Names</th>\n",
       "      <th>Team_rank</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Points</th>\n",
       "      <th>Matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia AUS</td>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "      <td>2,945</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India IND  29 3</td>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>3,344</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England ENG  27</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>3,100</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South Africa SA</td>\n",
       "      <td>5</td>\n",
       "      <td>107</td>\n",
       "      <td>2,137</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pakistan PAK  2</td>\n",
       "      <td>6</td>\n",
       "      <td>97</td>\n",
       "      <td>2,32</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bangladesh BAN</td>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>2,43</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>West Indies WI</td>\n",
       "      <td>8</td>\n",
       "      <td>82</td>\n",
       "      <td>2,22</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka SL  2</td>\n",
       "      <td>9</td>\n",
       "      <td>78</td>\n",
       "      <td>1,87</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0   Afghanistan AF</td>\n",
       "      <td>10</td>\n",
       "      <td>62</td>\n",
       "      <td>1,05</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1   Netherlands NE</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>5 24</td>\n",
       "      <td>ED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Team_Names Team_rank Rating Points Matches\n",
       "0     Australia AUS         2      118  2,945     25 \n",
       "1     India IND  29 3       3      115  3,344     29 \n",
       "2     England ENG  27       4      115  3,100     27 \n",
       "3     South Africa SA       5      107  2,137     20 \n",
       "4     Pakistan PAK  2       6       97   2,32      24\n",
       "5     Bangladesh BAN        7       90   2,43      27\n",
       "6     West Indies WI        8       82   2,22      27\n",
       "7     Sri Lanka SL  2       9       78   1,87      24\n",
       "8  0   Afghanistan AF       10      62   1,05      17\n",
       "9  1   Netherlands NE       11      50   5 24     ED "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top10_teams.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### B. Top 10 ODI Batsmen in men along with the records of their team and rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scarp data from multiple pages\n",
    "\n",
    "cricket_player = requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\")\n",
    "soup = BeautifulSoup(cricket_player.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket_player = soup.find_all(\"td\", class_=\"table-body__cell rankings-table__name name\") \n",
    "Top_player_names = []\n",
    "\n",
    "for i in cricket_player:\n",
    "    Top_player_names.append(i.text.replace(\"\\n\",\" \"))        \n",
    "#Top_player_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket_player = soup.find_all(\"td\", class_=\"table-body__cell nationality-logo rankings-table__team\") \n",
    "player_country = []\n",
    "\n",
    "for i in cricket_player:\n",
    "    player_country.append(i.text.replace(\"\\n\",\" \"))   \n",
    "#player_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket_player = soup.find_all(\"td\", class_=\"table-body__cell rating\") \n",
    "Rating = []\n",
    "\n",
    "for i in cricket_player:\n",
    "    Rating.append(i.text.replace(\"\\n\",\" \"))    \n",
    "#Rating\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket_player = soup.find_all(\"td\", class_=\"table-body__cell table-body__cell--position u-text-right\") \n",
    "Rank = []\n",
    "\n",
    "for i in cricket_player:\n",
    "    Rank.append(i.text.replace(\"\\n\",\" \"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top_Batsman =pd.DataFrame({})\n",
    "Top_Batsman['Rank'] = Rank\n",
    "Top_Batsman['Top_player_names'] = Top_player_names\n",
    "Top_Batsman['player_country'] = player_country\n",
    "Top_Batsman['Rating'] = Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Top_player_names</th>\n",
       "      <th>player_country</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>Francois du Plessis</td>\n",
       "      <td>SA</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Rank       Top_player_names  \\\n",
       "0                                2                     Virat Kohli    \n",
       "1                                3                    Rohit Sharma    \n",
       "2                                4                     Ross Taylor    \n",
       "3                                5                     Aaron Finch    \n",
       "4                                6                  Jonny Bairstow    \n",
       "5                                7                    Fakhar Zaman    \n",
       "6                                              Francois du Plessis    \n",
       "7                                9                    David Warner    \n",
       "8                                                        Shai Hope    \n",
       "9                               11                 Quinton de Kock    \n",
       "\n",
       "  player_country Rating  \n",
       "0           IND     857  \n",
       "1           IND     825  \n",
       "2            NZ     801  \n",
       "3           AUS     791  \n",
       "4           ENG     785  \n",
       "5           PAK     778  \n",
       "6            SA     778  \n",
       "7           AUS     773  \n",
       "8            WI     773  \n",
       "9            SA     756  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_Batsman.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii)  Top 10 ODI bowlers along with the records of their team and rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scarp data from multiple pages\n",
    "\n",
    "cricket_player = requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\")\n",
    "soup = BeautifulSoup(cricket_player.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket_player = soup.find_all(\"td\", class_=\"table-body__cell rankings-table__name name\")\n",
    "Top_player_names = []\n",
    "\n",
    "for i in cricket_player:\n",
    "    Top_player_names.append(i.text.replace(\"\\n\",\" \"))      \n",
    "#Top_player_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket_player = soup.find_all(\"td\", class_=\"table-body__cell nationality-logo rankings-table__team\")\n",
    "player_country = []\n",
    "\n",
    "for i in cricket_player:\n",
    "    player_country.append(i.text.replace(\"\\n\",\" \"))   \n",
    "#player_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket_player = soup.find_all(\"td\", class_=\"table-body__cell rating\")\n",
    "Rating = []\n",
    "\n",
    "for i in cricket_player:\n",
    "    Rating.append(i.text.replace(\"\\n\",\" \"))   \n",
    "#Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket_player = soup.find_all(\"td\", class_=\"table-body__cell table-body__cell--position u-text-right\") \n",
    "Rank = []\n",
    "\n",
    "for i in cricket_player:\n",
    "    Rank.append(i.text.replace(\"\\n\",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top_Bowlers =pd.DataFrame({})\n",
    "Top_Bowlers['Rank'] = Rank\n",
    "Top_Bowlers['Top_player_names'] = Top_player_names\n",
    "Top_Bowlers['player_country'] = player_country\n",
    "Top_Bowlers['Rating'] = Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Top_player_names</th>\n",
       "      <th>player_country</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>SA</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9             Thi...</td>\n",
       "      <td>Pat Cummins</td>\n",
       "      <td>AUS</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10             Th...</td>\n",
       "      <td>Mustafizur Rahman</td>\n",
       "      <td>BAN</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>Mohammad Amir</td>\n",
       "      <td>PAK</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Rank     Top_player_names  \\\n",
       "0                                        2                  Mehedi Hasan    \n",
       "1                                        3              Mujeeb Ur Rahman    \n",
       "2                                        4                    Matt Henry    \n",
       "3                                        5                Jasprit Bumrah    \n",
       "4                                        6                 Kagiso Rabada    \n",
       "5                                        7                  Chris Woakes    \n",
       "6                                        8                Josh Hazlewood    \n",
       "7                               9             Thi...         Pat Cummins    \n",
       "8                               10             Th...   Mustafizur Rahman    \n",
       "9                                       11                 Mohammad Amir    \n",
       "\n",
       "  player_country Rating  \n",
       "0           BAN     713  \n",
       "1           AFG     708  \n",
       "2            NZ     691  \n",
       "3           IND     690  \n",
       "4            SA     666  \n",
       "5           ENG     665  \n",
       "6           AUS     660  \n",
       "7           AUS     646  \n",
       "8           BAN     645  \n",
       "9           PAK     638  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_Bowlers.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape: \n",
    " Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the 10 ODI teams in women’s cricket\n",
    "cricket = requests.get(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")\n",
    "soup = BeautifulSoup(cricket.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cricket = soup.find_all(\"td\", class_=\"table-body__cell table-body__cell--position u-text-right\")\n",
    "Ranking = []\n",
    "\n",
    "for i in cricket:\n",
    "    Ranking.append(i.text.replace(\"\\n\",\" \"))    \n",
    "len(Ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket = soup.find_all(\"span\", class_=\"u-hide-phablet\") \n",
    "Country = []\n",
    "\n",
    "for i in cricket:\n",
    "    Country.append(i.text.replace(\"\\n\",\" \"))\n",
    "    \n",
    "Country=Country[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cricket = soup.find_all(\"td\", class_=\"table-body__cell u-text-right rating\") \n",
    "Rating = []\n",
    "\n",
    "for i in cricket:\n",
    "    Rating.append(i.text.replace(\"\\n\",\" \"))\n",
    "    \n",
    "len(Rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket = soup.find_all(\"td\", class_=\"table-body__cell u-center-text\") \n",
    "Matches_and_Point = []\n",
    "\n",
    "for i in cricket:\n",
    "    Matches_and_Point.append(i.text.replace(\"\\n\",\" \"))\n",
    "    \n",
    "len(Matches_and_Point)\n",
    "Matches_and_Point = Matches_and_Point[:9] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Country</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Matches_and_Point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Australia</td>\n",
       "      <td>118</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>117</td>\n",
       "      <td>2,828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>England</td>\n",
       "      <td>111</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>India</td>\n",
       "      <td>93</td>\n",
       "      <td>1,993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>85</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>West Indies</td>\n",
       "      <td>73</td>\n",
       "      <td>2,226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>61</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>47</td>\n",
       "      <td>1,947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ranking       Country Rating Matches_and_Point\n",
       "0       2     Australia    118                24\n",
       "1       3  South Africa    117             2,828\n",
       "2       4       England    111                17\n",
       "3       5         India     93             1,993\n",
       "4       6   New Zealand     85                20\n",
       "5       7   West Indies     73             2,226\n",
       "6       8      Pakistan     61                21\n",
       "7       9    Bangladesh     47             1,947\n",
       "8      10     Sri Lanka     13                12"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_Women_Team =pd.DataFrame({})\n",
    "\n",
    "Top_Women_Team['Ranking'] = Ranking\n",
    "Top_Women_Team['Country'] = Country\n",
    "Top_Women_Team['Rating'] = Rating\n",
    "Top_Women_Team['Matches_and_Point'] = Matches_and_Point\n",
    "Top_Women_Team.head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Top 10 women’s ODI players along with the records of their team and rating.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrap the ODI players \n",
    "\n",
    "cricket_player = requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\")\n",
    "soup = BeautifulSoup(cricket_player.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket_player = soup.find_all(\"td\", class_=\"table-body__cell rankings-table__name name\") \n",
    "Top_player_names = []\n",
    "\n",
    "for i in cricket_player:\n",
    "    Top_player_names.append(i.text.replace(\"\\n\",\" \"))\n",
    "        \n",
    "#Top_player_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket_player = soup.find_all(\"td\", class_=\"table-body__cell nationality-logo rankings-table__team\")\n",
    "player_country = []\n",
    "\n",
    "for i in cricket_player:\n",
    "    player_country.append(i.text.replace(\"\\n\",\" \"))   \n",
    "#player_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket_player = soup.find_all(\"td\", class_=\"table-body__cell rating\") \n",
    "Rating = []\n",
    "\n",
    "for i in cricket_player:\n",
    "    Rating.append(i.text.replace(\"\\n\",\" \"))   \n",
    "#Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket_player = soup.find_all(\"td\", class_=\"table-body__cell table-body__cell--position u-text-right\") \n",
    "Rank = []\n",
    "\n",
    "for i in cricket_player:\n",
    "    Rank.append(i.text.replace(\"\\n\",\" \"))\n",
    "#Rank   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Top_player_names</th>\n",
       "      <th>player_country</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td>SA</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9             Thi...</td>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10             Th...</td>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11             Th...</td>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Rank     Top_player_names  \\\n",
       "0                                        2                   Lizelle Lee    \n",
       "1                                        3                  Alyssa Healy    \n",
       "2                                        4               Stafanie Taylor    \n",
       "3                                        5                   Meg Lanning    \n",
       "4                                        6             Amy Satterthwaite    \n",
       "5                                        7               Smriti Mandhana    \n",
       "6                                        8                   Mithali Raj    \n",
       "7                               9             Thi...      Natalie Sciver    \n",
       "8                               10             Th...     Laura Wolvaardt    \n",
       "9                               11             Th...        Ellyse Perry    \n",
       "\n",
       "  player_country Rating  \n",
       "0            SA     758  \n",
       "1           AUS     756  \n",
       "2            WI     746  \n",
       "3           AUS     723  \n",
       "4            NZ     715  \n",
       "5           IND     710  \n",
       "6           IND     709  \n",
       "7           ENG     685  \n",
       "8            SA     683  \n",
       "9           AUS     679  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_Women_Batsman =pd.DataFrame({})\n",
    "\n",
    "Top_Women_Batsman['Rank'] = Rank\n",
    "Top_Women_Batsman['Top_player_names'] = Top_player_names\n",
    "Top_Women_Batsman['player_country'] = player_country\n",
    "Top_Women_Batsman['Rating'] = Rating\n",
    "Top_Women_Batsman.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii)  Top 10 women’s ODI all-rounder along with the records of their team and rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scarp data from multiple pages\n",
    "\n",
    "cricket_player = requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\")\n",
    "soup = BeautifulSoup(cricket_player.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket_player = soup.find_all(\"td\", class_=\"table-body__cell rankings-table__name name\") #scarp the top players \n",
    "Top_player_names = []\n",
    "\n",
    "for i in cricket_player:\n",
    "    Top_player_names.append(i.text.replace(\"\\n\",\" \"))\n",
    "        \n",
    "#Top_player_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket_player = soup.find_all(\"td\", class_=\"table-body__cell nationality-logo rankings-table__team\") \n",
    "player_country = []\n",
    "\n",
    "for i in cricket_player:\n",
    "    player_country.append(i.text.replace(\"\\n\",\" \"))\n",
    "    \n",
    "#player_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket_player = soup.find_all(\"td\", class_=\"table-body__cell rating\") #scarp the players\n",
    "Rating = []\n",
    "\n",
    "for i in cricket_player:\n",
    "    Rating.append(i.text.replace(\"\\n\",\" \"))\n",
    "    \n",
    "#Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket_player = soup.find_all(\"td\", class_=\"table-body__cell table-body__cell--position u-text-right\") \n",
    "Rank = []\n",
    "\n",
    "for i in cricket_player:\n",
    "    Rank.append(i.text.replace(\"\\n\",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Top_player_names</th>\n",
       "      <th>player_country</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This player has moved down in the ranking...</td>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8             Thi...</td>\n",
       "      <td>Dane van Niekerk</td>\n",
       "      <td>SA</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9             Thi...</td>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10             Th...</td>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>Shikha Pandey</td>\n",
       "      <td>IND</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Rank    Top_player_names  \\\n",
       "0        This player has moved down in the ranking...       Ellyse Perry    \n",
       "1                                         3              Stafanie Taylor    \n",
       "2                                         4               Natalie Sciver    \n",
       "3                                         5                Deepti Sharma    \n",
       "4                                         6                Jess Jonassen    \n",
       "5                                         7             Ashleigh Gardner    \n",
       "6                                8             Thi...   Dane van Niekerk    \n",
       "7                                9             Thi...      Sophie Devine    \n",
       "8                                10             Th...        Amelia Kerr    \n",
       "9                                                        Katherine Brunt    \n",
       "10                                       12                Shikha Pandey    \n",
       "\n",
       "   player_country Rating  \n",
       "0            AUS     418  \n",
       "1             WI     410  \n",
       "2            ENG     349  \n",
       "3            IND     343  \n",
       "4            AUS     307  \n",
       "5            AUS     252  \n",
       "6             SA     243  \n",
       "7             NZ     242  \n",
       "8             NZ     236  \n",
       "9            ENG     236  \n",
       "10           IND     204  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_All_rounder =pd.DataFrame({})\n",
    "Top_All_rounder['Rank'] = Rank\n",
    "Top_All_rounder['Top_player_names'] = Top_player_names\n",
    "Top_All_rounder['player_country'] = player_country\n",
    "Top_All_rounder['Rating'] = Rating\n",
    "Top_All_rounder.head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The \n",
    "scraped data should include Product Name, Price, Image URL and Average Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\programdata\\anaconda3\\lib\\site-packages (4.3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping the amazon website \n",
    "Amazon = requests.get(\"https://www.amazon.in/s?k=under+20000+best+smartphone&crid=3AF2MHZJF09WN&sprefix=under+20000%2Caps%2C556&ref=nb_sb_ss_ts-doa-p_1_11\")\n",
    "soup = BeautifulSoup(Amazon.content, 'lxml')\n",
    "Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = soup.find(\"span\", attrs={\"id\": 'productTitle'})\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Amazon = soup.find_all(\"h2\", class_=\"a-size-mini a-spacing-none a-color-base s-line-clamp-2\") \n",
    "Mobiles_names = []\n",
    "\n",
    "for i in Amazon:\n",
    "    Mobiles_names.append(i.text.strip())\n",
    "        \n",
    "len(Mobiles_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Amazon = soup.find_all(\"span\", class_=\"a-price-whole\") \n",
    "Mobiles_Price = []\n",
    "\n",
    "for i in Amazon:\n",
    "    Mobiles_Price.append(i.text.replace(\"\\n\",\" \"))\n",
    "        \n",
    "len(Mobiles_Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "Amazon = soup.find_all(\"span\", class_=\"a-icon-alt\") \n",
    "Rating = []\n",
    "\n",
    "for i in Amazon:\n",
    "    Rating.append(i.text.replace(\"\\n\",\" \"))\n",
    "        \n",
    "len(Rating)\n",
    "\n",
    "# selecting only first 16 elements \n",
    "Rating = Rating[:16]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mobiles_names</th>\n",
       "      <th>Mobiles_Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samsung Galaxy M11 (Metallic Blue, 4GB RAM, 64...</td>\n",
       "      <td>8,999</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oppo A31 (Fantasy White, 6GB RAM, 128GB Storag...</td>\n",
       "      <td>11,990</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Samsung Galaxy M02s (Black,4GB RAM, 64GB Stora...</td>\n",
       "      <td>9,999</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage)| 500...</td>\n",
       "      <td>8,799</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samsung Galaxy M21 (Midnight Blue, 4GB RAM, 64...</td>\n",
       "      <td>12,499</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Redmi Note 9 (Pebble Grey, 4GB RAM 64GB Storag...</td>\n",
       "      <td>10,999</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Samsung Galaxy M31 (Ocean Blue, 6GB RAM, 128GB...</td>\n",
       "      <td>14,999</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Redmi Note 10 (Aqua Green, 6GB RAM, 128GB Stor...</td>\n",
       "      <td>14,499</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Oppo F17 (Dynamic Orange, 6GB RAM, 128GB Stora...</td>\n",
       "      <td>16,990</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Samsung Galaxy M11 (Violet, 4GB RAM, 64GB Stor...</td>\n",
       "      <td>8,999</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Oppo A31 (Mystery Black, 6GB RAM, 128GB Storag...</td>\n",
       "      <td>11,990</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Redmi 9A (Nature Green, 2GB RAM, 32GB Storage)...</td>\n",
       "      <td>6,999</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Vivo Y11 (Agate Red, 3GB RAM, 32GB Storage) wi...</td>\n",
       "      <td>8,990</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Redmi 9 (Carbon Black, 4GB RAM, 64GB Storage) ...</td>\n",
       "      <td>8,799</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Redmi 9 (Sporty Orange, 4GB RAM, 64GB Storage)...</td>\n",
       "      <td>8,799</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Mobiles_names Mobiles_Price  \\\n",
       "0   Samsung Galaxy M11 (Metallic Blue, 4GB RAM, 64...         8,999   \n",
       "1   Oppo A31 (Fantasy White, 6GB RAM, 128GB Storag...        11,990   \n",
       "2   Samsung Galaxy M02s (Black,4GB RAM, 64GB Stora...         9,999   \n",
       "3   Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage)| 500...         8,799   \n",
       "4   Samsung Galaxy M21 (Midnight Blue, 4GB RAM, 64...        12,499   \n",
       "5   Redmi Note 9 (Pebble Grey, 4GB RAM 64GB Storag...        10,999   \n",
       "6   Samsung Galaxy M31 (Ocean Blue, 6GB RAM, 128GB...        14,999   \n",
       "7   Redmi Note 10 (Aqua Green, 6GB RAM, 128GB Stor...        14,499   \n",
       "8   Oppo F17 (Dynamic Orange, 6GB RAM, 128GB Stora...        16,990   \n",
       "9   Samsung Galaxy M11 (Violet, 4GB RAM, 64GB Stor...         8,999   \n",
       "10  Oppo A31 (Mystery Black, 6GB RAM, 128GB Storag...        11,990   \n",
       "11  Redmi 9A (Nature Green, 2GB RAM, 32GB Storage)...         6,999   \n",
       "12  Vivo Y11 (Agate Red, 3GB RAM, 32GB Storage) wi...         8,990   \n",
       "13  Redmi 9 (Carbon Black, 4GB RAM, 64GB Storage) ...         8,799   \n",
       "14  Redmi 9 (Sporty Orange, 4GB RAM, 64GB Storage)...         8,799   \n",
       "\n",
       "                Rating  \n",
       "0   4.2 out of 5 stars  \n",
       "1   4.2 out of 5 stars  \n",
       "2   4.1 out of 5 stars  \n",
       "3   4.2 out of 5 stars  \n",
       "4   4.2 out of 5 stars  \n",
       "5   4.3 out of 5 stars  \n",
       "6   4.3 out of 5 stars  \n",
       "7   4.1 out of 5 stars  \n",
       "8   4.1 out of 5 stars  \n",
       "9   4.1 out of 5 stars  \n",
       "10  4.2 out of 5 stars  \n",
       "11  4.2 out of 5 stars  \n",
       "12  4.3 out of 5 stars  \n",
       "13  4.2 out of 5 stars  \n",
       "14  4.2 out of 5 stars  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mobiles =pd.DataFrame({})\n",
    "\n",
    "Mobiles['Mobiles_names'] = Mobiles_names\n",
    "Mobiles['Mobiles_Price'] = Mobiles_Price\n",
    "Mobiles['Rating'] = Rating\n",
    "\n",
    "\n",
    "\n",
    "Mobiles.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Mobiles_name['Mobiles_names'] = Mobiles_name['Mobiles_names'].str.replace(r\"(\\s*\\[.*?\\]\\s*)\", \" \").str.strip()\n",
    "#Mobiles_name['Mobiles_names']\n",
    "\n",
    "Mobiles_name.loc[Mobiles_names,Mobiles_names].str.replace(r\"(\\s*\\[.*?\\]\\s*)\", \" \").str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a python program to extract information about the local weather from the National Weather Service \n",
    "website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day \n",
    "extended  forecast  display  for  the  city.  The  data  should  include  period,  short  description,  temperature  and \n",
    "description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page =requests.get('https://forecast.weather.gov/MapClick.php?CityName=San+Francisco+Plaza&state=NM&site=ABQ&textField1=33.6933&textField2=-108.766#.YLiTaKgzbDd')\n",
    "soup = BeautifulSoup(page.content, 'lxml')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Overnight',\n",
       " 'Thursday',\n",
       " 'ThursdayNight',\n",
       " 'Friday',\n",
       " 'FridayNight',\n",
       " 'Saturday',\n",
       " 'SaturdayNight',\n",
       " 'Sunday',\n",
       " 'SundayNight']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  extract all the tags having the job -title\n",
    "time_period=soup.find_all(\"p\", class_=\"period-name\") \n",
    "Time_period = []\n",
    "\n",
    "for i in time_period:\n",
    "    Time_period.append(i.text.replace(\"\\n\",\" \"))\n",
    "        \n",
    "Time_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather=soup.find_all(\"p\", class_=\"short-desc\")\n",
    "Weather = []\n",
    "\n",
    "for i in weather:\n",
    "    Weather.append(i.text.replace(\"\\n\",\" \"))\n",
    "len(Weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=soup.find_all(\"p\", class_=\"temp temp-low\")\n",
    "temp1=soup.find_all(\"p\", class_=\"temp temp-high\")\n",
    "Temp1 = []\n",
    "\n",
    "for i in temp:\n",
    "    Temp1.append(i.text.replace(\"\\n\",\" \"))\n",
    "    \n",
    "for i in temp1:\n",
    "    Temp1.append(i.text.replace(\"\\n\",\" \"))\n",
    "    \n",
    "len(Temp1)\n",
    "Temp1=Temp1[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_period</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Overnight</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>Low: 48 °F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>Mostly SunnythenScatteredT-storms</td>\n",
       "      <td>Low: 49 °F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ThursdayNight</td>\n",
       "      <td>Slight ChanceT-storms</td>\n",
       "      <td>Low: 49 °F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Friday</td>\n",
       "      <td>Partly Sunnythen ChanceT-storms</td>\n",
       "      <td>Low: 50 °F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FridayNight</td>\n",
       "      <td>Slight ChanceT-storms thenMostly Cloudy</td>\n",
       "      <td>Low: 48 °F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>Mostly Sunny</td>\n",
       "      <td>High: 86 °F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SaturdayNight</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>High: 84 °F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Mostly Sunny</td>\n",
       "      <td>High: 90 °F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SundayNight</td>\n",
       "      <td>Mostly Clear</td>\n",
       "      <td>High: 91 °F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time_period                                  Weather         Temp\n",
       "0      Overnight                            Partly Cloudy   Low: 48 °F\n",
       "1       Thursday        Mostly SunnythenScatteredT-storms   Low: 49 °F\n",
       "2  ThursdayNight                    Slight ChanceT-storms   Low: 49 °F\n",
       "3         Friday          Partly Sunnythen ChanceT-storms   Low: 50 °F\n",
       "4    FridayNight  Slight ChanceT-storms thenMostly Cloudy   Low: 48 °F\n",
       "5       Saturday                             Mostly Sunny  High: 86 °F\n",
       "6  SaturdayNight                            Mostly Cloudy  High: 84 °F\n",
       "7         Sunday                             Mostly Sunny  High: 90 °F\n",
       "8    SundayNight                             Mostly Clear  High: 91 °F"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Weather_report =pd.DataFrame({ })\n",
    "Weather_report['Time_period']=Time_period\n",
    "Weather_report['Weather']=Weather\n",
    "Weather_report['Temp']= Temp1\n",
    "Weather_report.head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a python program to scrape fresher job listings from ‘https://internshala.com/’. It should include job title, \n",
    "company name, CTC, and apply dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send request to the web server to get the soruce code of the page\n",
    "page =requests.get('https://internshala.com/fresher-jobs')\n",
    "soup = BeautifulSoup(page.content, 'lxml')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  extract all the tags having the job -title\n",
    "titles=soup.find_all('div', class_=\"heading_4_5 profile\") \n",
    "job_titles = []\n",
    "\n",
    "for i in titles:\n",
    "    job_titles.append(i.text.replace(\"\\n\",\" \"))\n",
    "        \n",
    "#job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  extract all the tags having compnay name\n",
    "company=soup.find_all('a', class_=\"link_display_like_text\") \n",
    "Company = []\n",
    "\n",
    "for i in company:    \n",
    "    Company.append(i.text.strip())\n",
    "        \n",
    "#Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Starts\\xa0Immediately',\n",
       " '4 - 8.5 LPA',\n",
       " \"3 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '6.62 - 7.95 LPA',\n",
       " \"3 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 4.5 LPA',\n",
       " \"3 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.5 LPA',\n",
       " \"2 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 4.5 LPA',\n",
       " \"2 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '5 - 6.5 LPA',\n",
       " \"2 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '4 - 7 LPA',\n",
       " \"1 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '4 - 7.2 LPA',\n",
       " \"1 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '4.5 - 6 LPA',\n",
       " \"1 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '5.5 - 6.5 LPA',\n",
       " \"1 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 5 LPA',\n",
       " \"1 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.5 LPA',\n",
       " \"1 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"1 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"30 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.1 LPA',\n",
       " \"30 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.5 LPA',\n",
       " \"30 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 4 LPA',\n",
       " \"30 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"30 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3.6 - 7 LPA',\n",
       " \"30 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 4.5 LPA',\n",
       " \"30 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '5.2 - 7 LPA',\n",
       " \"30 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 5 LPA',\n",
       " \"28 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 4.2 LPA',\n",
       " \"28 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.6 LPA',\n",
       " \"30 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '4.2 - 8.2 LPA',\n",
       " \"28 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 6 LPA',\n",
       " \"27 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"27 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3.6 LPA',\n",
       " \"27 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"30 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '5 - 6.5 LPA',\n",
       " \"27 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3.25 - 4 LPA',\n",
       " \"26 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3.75 LPA',\n",
       " \"26 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 4 LPA',\n",
       " \"25 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 4 LPA',\n",
       " \"25 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 5 LPA',\n",
       " \"25 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 5 LPA',\n",
       " \"24 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '5 - 8 LPA',\n",
       " \"24 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"24 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"24 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '4 LPA',\n",
       " \"24 Jun' 21\"]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  extract all the tags having CTC\n",
    "ctc=soup.find_all(\"div\", class_=\"item_body\")\n",
    "CTC = []\n",
    "\n",
    "for i in ctc:    \n",
    "    CTC.append(i.text.strip())\n",
    "        \n",
    "CTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "Job_details =pd.DataFrame({ })\n",
    "\n",
    "Job_details['Job_title']=job_titles\n",
    "Job_details['Company']=Company\n",
    "#Job_details['CTC']=CTC\n",
    "#We unable to do indexing with data  and ctc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business Marketing Manager</td>\n",
       "      <td>MentorBoxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>React Native Developer</td>\n",
       "      <td>Runners Planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Research And Communications Associate</td>\n",
       "      <td>Institute For Governance, Policies &amp; Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ProtonAutoML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science Django Developer</td>\n",
       "      <td>Markytics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Job_title  \\\n",
       "0              Business Marketing Manager    \n",
       "1                  React Native Developer    \n",
       "2   Research And Communications Associate    \n",
       "3                          Data Scientist    \n",
       "4           Data Science Django Developer    \n",
       "\n",
       "                                         Company  \n",
       "0                                     MentorBoxx  \n",
       "1                                 Runners Planet  \n",
       "2  Institute For Governance, Policies & Politics  \n",
       "3                                   ProtonAutoML  \n",
       "4                                      Markytics  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Job_details.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
